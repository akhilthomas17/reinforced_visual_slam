{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import lmbspecialops as sops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/misc/lmbraid19/thomasa/catkin_ws/src/reinforced_visual_slam/networks/depth_fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.my_networks import *\n",
    "from net.my_losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_names = [\n",
    "'rgb',\n",
    "'sparseInverseDepth',\n",
    "'sparseInverseDepthVariance'\n",
    "]\n",
    "\n",
    "FLAGS = {\n",
    "  'multi_gpu': True,\n",
    "  'batch_size':12,\n",
    "  'prefetch_buffer_size': 60,\n",
    "  'num_parallel_calls': 24,\n",
    "  'num_epochs':50,\n",
    "  'learning_rate':0.0005,\n",
    "  'data_format': \"channels_first\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_shuffler(training_file):\n",
    "  filename_records = tf.data.TextLineDataset(training_file)\n",
    "  dataset = filename_records.shuffle(buffer_size=50000)\n",
    "  return dataset\n",
    "\n",
    "def parse_load_augment(filename_line_):\n",
    "  filenames = tf.decode_csv(filename_line_, [[''], [''], [''], ['']])\n",
    "  print(filenames.output_shapes)\n",
    "  indices = tf.data.Dataset.from_tensors([0, 1, 2, 3])\n",
    "  print(indices.output_shapes)\n",
    "  image_files = tf.data.Dataset.zip((filenames, indices))\n",
    "  images = images_files.map(map_func=load_image, num_parallel_calls=4)\n",
    "  # add augmentation step here\n",
    "  depth_gt = images.range(0, 1)\n",
    "  train_images = images.range(1, 4)\n",
    "  d = dict(zip(feature_names, train_images)), depth_gt\n",
    "  return d\n",
    "\n",
    "def invert_clean(x, threshold=0.01):\n",
    "    mask =  tf.logical_and(tf.is_finite(x), x>threshold)\n",
    "    x_clean = tf.where(mask, tf.reciprocal(x), tf.zeros_like(x))\n",
    "    return x_clean\n",
    "\n",
    "def load_image(filename, index, data_format=FLAGS['data_format'], width=320, height=240, \n",
    "  resize=True, basepath = \"/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/\"):\n",
    "  image_string = tf.read_file(basepath + filename)\n",
    "  if index == 0:\n",
    "    # current image is depth groundtruth\n",
    "    image_decoded = tf.image.decode_png(image_string, dtype=tf.uint16)\n",
    "    image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "    image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "    image_decoded = tf.scalar_mul(0.0002, image_decoded)\n",
    "    # converting (and clean) depth to idepth and removing NaN's and Inf's\n",
    "    image_decoded = invert_clean(image_decoded)\n",
    "\n",
    "  elif index == 1:\n",
    "    # current image is rgb\n",
    "    image_decoded = tf.image.decode_png(image_string)\n",
    "    image_decoded = tf.reshape(image_decoded, [480, 640, 3])\n",
    "    image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "    # converting rgb to [0,1] from [0,255]\n",
    "    image_decoded = tf.scalar_mul(0.003926, image_decoded)\n",
    "\n",
    "  else:\n",
    "    # for both the sparse depth and variance\n",
    "    image_decoded = tf.decode_raw(image_string, tf.half)\n",
    "    image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "    image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "    image_decoded = replace_nonfinite(image_decoded)\n",
    "\n",
    "  if resize == True:\n",
    "    image_decoded = tf.image.resize_images(image_decoded, [height, width], align_corners=True)\n",
    "  if data_format == 'channels_first':\n",
    "    image_decoded = tf.transpose(image_decoded,[2,0,1])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = \"/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/rgbd_lsdDepth_train.txt\"\n",
    "dataset = dataset_shuffler(training_file)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_n_load(filename_line, data_format=FLAGS['data_format'], width=320, height=240):\n",
    "  filenames = tf.decode_csv(filename_line, [[''], [''], [''], ['']])\n",
    "  images = []\n",
    "  basepath = \"/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/\"\n",
    "  for cnt in range(4):\n",
    "      image_string = tf.read_file(basepath + filenames[cnt])\n",
    "      if cnt < 2:\n",
    "        if cnt == 0:\n",
    "          image_decoded = tf.image.decode_png(image_string, dtype=tf.uint16)\n",
    "          image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "        else:\n",
    "          image_decoded = tf.image.decode_png(image_string)\n",
    "          image_decoded = tf.reshape(image_decoded, [480, 640, 3])\n",
    "        image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "      else:\n",
    "        image_decoded = tf.decode_raw(image_string, tf.half)\n",
    "        image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "        image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "        image_decoded = replace_nonfinite(image_decoded)\n",
    "      image_decoded = tf.image.resize_images(image_decoded, [height, width], \n",
    "        align_corners=True)\n",
    "      if data_format == 'channels_first':\n",
    "        image_decoded = tf.transpose(image_decoded,[2,0,1])\n",
    "      images.append(image_decoded)\n",
    "          \n",
    "  depth_gt = tf.scalar_mul(0.0002, images[0])\n",
    "  # converting depth to idepth and removing NaN's and Inf's\n",
    "  #idepth_gt = tf.reciprocal(depth_gt)\n",
    "  #idepth_gt_clean = replace_nonfinite(idepth_gt)\n",
    "  idepth_gt_clean = invert_clean(depth_gt)\n",
    "  del images[0]\n",
    "  # converting rgb to [0,1] from [0,255]\n",
    "  images[0] = tf.scalar_mul(0.003926, images[0])\n",
    "  #d = dict(zip(feature_names, images)), idepth_gt_clean\n",
    "  d = dict(zip(feature_names, images)), idepth_gt_clean\n",
    "  return d\n",
    "\n",
    "def dataset_shuffler(training_file):\n",
    "  filename_records = tf.data.TextLineDataset(training_file)\n",
    "  dataset = filename_records.shuffle(buffer_size=50000)\n",
    "  return dataset\n",
    "\n",
    "def input_fn(dataset, shuffle=False):\n",
    "  dataset = dataset.map(map_func=parse_n_load, num_parallel_calls=FLAGS['num_parallel_calls'])\n",
    "  #dataset.apply(tf.contrib.data.map_and_batch(map_func=parse_n_load, num_parallel_calls=FLAGS.num_parallel_calls,\n",
    "   #                                           batch_size=FLAGS.batch_size))\n",
    "  dataset = dataset.repeat(FLAGS['num_epochs'])\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "  dataset = dataset.batch(batch_size=FLAGS['batch_size'])\n",
    "  dataset = dataset.prefetch(buffer_size=FLAGS['prefetch_buffer_size'])\n",
    "  iterator = dataset.make_one_shot_iterator()\n",
    "  features, label = iterator.get_next()\n",
    "  return features, label\n",
    "\n",
    "def train_input_fn():\n",
    "  training_file = \"/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/rgbd_lsdDepth_train.txt\"\n",
    "  #basepath = os.path.dirname(training_file)\n",
    "  dataset = dataset_shuffler(training_file)\n",
    "  #dataset = tf.data.TextLineDataset(training_file)\n",
    "  features, label = input_fn(dataset, shuffle=False)\n",
    "  return features, label\n",
    "\n",
    "def replace_nonfinite(x):\n",
    "    mask = tf.is_finite(x)\n",
    "    x_clean = tf.where(mask, x, tf.zeros_like(x))\n",
    "    return x_clean\n",
    "\n",
    "def validate_batch_size_for_multi_gpu(batch_size):\n",
    "  \"\"\"For multi-gpu, batch-size must be a multiple of the number of GPUs.\n",
    "  Note that this should eventually be handled by replicate_model_fn\n",
    "  directly. Multi-GPU support is currently experimental, however,\n",
    "  so doing the work here until that feature is in place.\n",
    "  Args:\n",
    "    batch_size: the number of examples processed in each training batch.\n",
    "  Raises:\n",
    "    ValueError: if no GPUs are found, or selected batch_size is invalid.\n",
    "  \"\"\"\n",
    "  from tensorflow.python.client import device_lib  # pylint: disable=g-import-not-at-top\n",
    "\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  num_gpus = sum([1 for d in local_device_protos if d.device_type == 'GPU'])\n",
    "  if not num_gpus:\n",
    "    raise ValueError('Multi-GPU mode was specified, but no GPUs '\n",
    "                     'were found. To use CPU, run without --multi_gpu.')\n",
    "\n",
    "  remainder = batch_size % num_gpus\n",
    "  if remainder:\n",
    "    err = ('When running with multiple GPUs, batch size '\n",
    "           'must be a multiple of the number of available GPUs. '\n",
    "           'Found {} GPUs with a batch size of {}; try --batch_size={} instead.'\n",
    "          ).format(num_gpus, batch_size, batch_size - remainder)\n",
    "    raise ValueError(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "  rgb = features['rgb']\n",
    "  sparseIdepth = features['sparseInverseDepth']\n",
    "  sparseIdepthVar = features['sparseInverseDepthVariance']\n",
    "  inputs = [rgb, sparseIdepth, sparseIdepthVar]\n",
    "\n",
    "  # summaries for images\n",
    "  if params.get('data_format') == \"channels_first\":\n",
    "    rgb_nhwc = tf.transpose(rgb, [0,2,3,1])\n",
    "    sparseIdepth_nhwc = tf.transpose(sparseIdepth, [0,2,3,1])\n",
    "    sparseIdepthVar_nhwc = tf.transpose(sparseIdepthVar, [0,2,3,1])\n",
    "  else:\n",
    "    rgb_nhwc = rgb\n",
    "    sparseIdepth_nhwc = sparseIdepth\n",
    "    sparseIdepthVar_nhwc = sparseIdepthVar\n",
    "  tf.summary.image('rgb', rgb_nhwc, max_outputs=1)\n",
    "  tf.summary.image('sparseIdepth', sparseIdepth_nhwc, max_outputs=1)\n",
    "  tf.summary.image('sparseIdepthVar', sparseIdepthVar_nhwc, max_outputs=1)\n",
    "\n",
    "  model = NetworkV02()\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    depth = model(inputs, params.get('data_format'))\n",
    "    predictions = {\n",
    "        'depth': depth,\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.PREDICT, \n",
    "                                  predictions=predictions, \n",
    "                                  export_outputs={'depth': tf.estimator.export.PredictOutput(predictions)})\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    learning_rate_base = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_base, tf.train.get_or_create_global_step(), \n",
    "      decay_rate=0.8, decay_steps=100000, staircase=False)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    # If we are running multi-GPU, we need to wrap the optimizer.\n",
    "    if params.get('multi_gpu'):\n",
    "      optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "    \n",
    "    depth = model(inputs, data_format=params.get('data_format'))\n",
    "    loss = pointwise_l1_loss(inp=depth, gt=labels, data_format=params.get('data_format'))\n",
    "    if params.get('data_format') == \"channels_first\":\n",
    "      depth_nhwc = tf.transpose(depth, [0,2,3,1])\n",
    "      labels_nhwc = tf.transpose(labels, [0,2,3,1])\n",
    "    else:\n",
    "      depth_nhwc = depth\n",
    "      labels_nhwc = labels\n",
    "    tf.summary.image('depthPredicted', depth_nhwc, max_outputs=1)\n",
    "    tf.summary.image('depthGt', labels_nhwc, max_outputs=1)  \n",
    "\n",
    "    # Save scalars to Tensorboard output.\n",
    "    tf.summary.scalar('train_loss', loss)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, \n",
    "      train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    depth = model(inputs, params.get('data_format'))\n",
    "    loss = pointwise_l2_loss(inp=labels, gt=depth, data_format=params.get('data_format'))\n",
    "    return tf.estimator.EstimatorSpec(mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                      loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trainer(model_dir_name, training_steps):\n",
    "  \"\"\"Run training and eval loop for lsd depth fusion network.\n",
    "  \"\"\"\n",
    "  model_function = model_fn\n",
    "  hooks = [tf_debug.LocalCLIDebugHook()]\n",
    "  #hooks = [tf_debug.TensorBoardDebugHook(\"localhost:6064\")] (tf 1.5+)\n",
    "\n",
    "  if FLAGS['multi_gpu']:\n",
    "    validate_batch_size_for_multi_gpu(FLAGS['batch_size'])\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_fn, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "  data_format = 'channels_first'\n",
    "  model_base_dir = \"/misc/lmbraid19/thomasa/catkin_ws/src/reinforced_visual_slam/networks/depth_fusion/training\"\n",
    "  model_dir = os.path.join(model_base_dir, model_dir_name)\n",
    "\n",
    "  lsd_depth_fuser = tf.estimator.Estimator(\n",
    "    model_fn=model_function,\n",
    "    model_dir=model_dir,\n",
    "    params={\n",
    "    'data_format': data_format,\n",
    "    'multi_gpu': FLAGS['multi_gpu']\n",
    "    })\n",
    "\n",
    "  # Train and evaluate model.\n",
    "  #for _ in range(FLAGS['num_epochs'] // flags_obj.epochs_between_evals):\n",
    "  lsd_depth_fuser.train(input_fn=train_input_fn, steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = train_input_fn()\n",
    "rgb = features['rgb']\n",
    "sparseIdepth = features['sparseInverseDepth']\n",
    "sparseIdepthVar = features['sparseInverseDepthVariance']\n",
    "inputs = [rgb, sparseIdepth, sparseIdepthVar]\n",
    "#tf.summary.image('rgb', rgb, max_outputs=6)\n",
    "#tf.summary.image('sparseIdepth', sparseIdepth, max_outputs=6)\n",
    "#tf.summary.image('sparseIdepthVar', sparseIdepthVar, max_outputs=6)\n",
    "inputs = [rgb, sparseIdepth, sparseIdepthVar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "inputs_pr = sess.run(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pr = sess.run(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 240, 320)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pr[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.374504"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(labels_pr[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_string = tf.read_file('/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/rgbd_dataset_freiburg1_360/99_1305031803.381500_42_depthGT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess2 = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_string = sess2.run(image_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_decoded = tf.image.decode_png(image_string, dtype=tf.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "image_decoded = tf.cast(image_decoded, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshaped = tf.image.resize_images(image_decoded, [240, 320], align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_gt = tf.transpose(image_reshaped,[2,0,1])\n",
    "depth_gt = tf.scalar_mul(0.0002, depth_gt)\n",
    "depths = [image_decoded, image_reshaped, depth_gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idepth_gt = tf.reciprocal(depth_gt)\n",
    "idepth_gt_clean = replace_nonfinite(idepth_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idepth_gt_clean_ = sess2.run(idepth_gt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_ = sess2.run(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_decoded = tf.reshape(image_decoded, [480, 640, 1])\n",
    "image_decoded = tf.cast(image_decoded, tf.float32)\n",
    "image_decoded = tf.transpose(image_decoded,[2,0,1])\n",
    "depth_gt = tf.scalar_mul(0.0002, image_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_decoded = sess2.run(image_decoded)\n",
    "depth_gt_ = sess2.run(depth_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idepth_gt_clean_.shape)\n",
    "print(idepth_gt_clean_.dtype)\n",
    "print(np.max(idepth_gt_clean_))\n",
    "print(np.min(idepth_gt_clean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idepth_ = np.transpose(idepth_gt_clean_, [1, 2 ,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idepth_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(idepth_[:,:,0], cmap='hot')\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetworkV02()\n",
    "depth = model(inputs, data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = pointwise_l1_loss(inp=depth, gt=labels, data_format='channels_first')\n",
    "loss2 = pointwise_l2_loss(inp=depth, gt=labels, data_format='channels_first')\n",
    "loss = [loss1, loss2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss_pr = sess.run(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = depth - labels\n",
    "sop_diff = sops.replace_nonfinite(diff)\n",
    "diffs = [diff, sop_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sop_pow = sop_diff**2\n",
    "diff_pow = diff**2\n",
    "pows = [diff_pow, sop_pow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_sop = tf.pow(sop_diff, 2)\n",
    "pow_diff = tf.pow(diff, 2)\n",
    "pows_tf_ = [pow_diff, pow_sop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pows_tf_pr = sess.run(pows_tf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isinf(pows_tf_pr[1]).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.isnan(diffs_pr[1]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pr = sess.run(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_pr = sess.run(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pr = sess3.run(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(inputs_pr[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(labels_pr) * 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmax(1/depth_pr))\n",
    "print(np.min(depth_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_pr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetworkV01()\n",
    "depth = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "depth_pr = sess.run(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/misc/lmbraid19/thomasa/catkin_ws/src/reinforced_visual_slam/networks/depth_fusion/training/02\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SimpleNetwork()\n",
    "#model.compile(optimizer= tf.keras.optimizers.Adam(0.001), loss=pointwise_l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trainer(flags_obj):\n",
    "  \"\"\"Run MNIST training and eval loop.\n",
    "  Args:\n",
    "    flags_obj: An object containing parsed flag values.\n",
    "  \"\"\"\n",
    "\n",
    "  model_function = model_fn\n",
    "\n",
    "  if flags_obj.multi_gpu:\n",
    "    validate_batch_size_for_multi_gpu(flags_obj.batch_size)\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_fn, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "  data_format = flags_obj.data_format\n",
    "  if data_format is None:\n",
    "    data_format = ('channels_first'\n",
    "                   if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "\n",
    "  lsd_depth_fuser = tf.estimator.Estimator(\n",
    "      model_fn=model_function,\n",
    "      model_dir=flags_obj.model_dir,\n",
    "      params={\n",
    "      'data_format': data_format,\n",
    "      'multi_gpu': flags_obj.multi_gpu\n",
    "      })\n",
    "\n",
    "  # Train and evaluate model.\n",
    "  for _ in range(10):\n",
    "    lsd_depth_fuser.train(input_fn=train_input_fn(dataset.range(train_ind)))\n",
    "    eval_results = lsd_depth_fuser.evaluate(input_fn=eval_input_fn)\n",
    "    print('\\nEvaluation results:\\n\\t%s\\n' % eval_results)\n",
    "\n",
    "    if model_helpers.past_stop_threshold(flags_obj.stop_threshold,\n",
    "                                         eval_results['loss']):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    lsd_depth_fuser.train(input_fn=train_input_fn(dataset.range(train_ind)))\n",
    "    eval_results = lsd_depth_fuser.evaluate(input_fn=train_input_fn(dataset.range(train_ind, train_ind+100000)))\n",
    "    print('\\nEvaluation results:\\n\\t%s\\n' % eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To walk throught subdirectories of the training directory and \n",
    "make a single file containing relative path to each of the training samples.\n",
    "Each line in file would be:\n",
    "    depth_gt,rgb,sparseDepth,sparseDepthVar\n",
    "\"\"\"\n",
    "import os\n",
    "with open(\"/misc/lmbraid19/thomasa/datasets/rgbd_lsdDepth_train.txt\", \"w+\") as train_file:\n",
    "    cnt = 0\n",
    "    for root, directories, filenames in os.walk('/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/'):\n",
    "        for files in sorted(filenames):\n",
    "            cnt += 1\n",
    "            if cnt < 4:\n",
    "                sep = \",\"\n",
    "            else:\n",
    "                sep = \"\\r\\n\"\n",
    "                cnt = 0\n",
    "            #print(files)\n",
    "            #print(os.path.basename(os.path.normpath(root)))\n",
    "            train_file.write( os.path.basename(os.path.normpath(root)) + \"/\" + files + sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder = \"/misc/lmbraid19/thomasa/datasets\"\n",
    "folder_parent = os.path.dirname(folder)\n",
    "print(folder_parent)\n",
    "os.path.join(folder_parent, \"lsdDepth.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = (\"enthanu \"\n",
    "     \"nannayikoode\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "'rgb',\n",
    "'sparseInverseDepth',\n",
    "'sparseInverseDepthVariance'\n",
    "]\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork( object ):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    self.FLAGS = {\n",
    "    'batch':8,\n",
    "    }\n",
    "\n",
    "    # starting conv rgb\n",
    "    #self.convrgb = tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=tf.nn.relu, input_shape=(self.FLAGS['batch'],640,480,3), padding=\"same\")\n",
    "    self.convrgb = tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "\n",
    "    # starting conv sparse\n",
    "    #self.convsparse = tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=tf.nn.relu, input_shape=(self.FLAGS['batch'],640,480,1), padding=\"same\")\n",
    "    self.convsparse = tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "\n",
    "    # encoder network:\n",
    "    self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.pool1 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "\n",
    "    self.conv2 = tf.keras.layers.Conv2D(filters=63, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.pool2 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "\n",
    "    self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.pool3 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "\n",
    "    # decoder network:\n",
    "\n",
    "    self.deconv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.upsample3 = tf.keras.layers.UpSampling2D(size=2)\n",
    "\n",
    "    self.deconv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.upsample2 = tf.keras.layers.UpSampling2D(size=2)\n",
    "\n",
    "    self.deconv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation=tf.nn.relu, padding=\"same\")\n",
    "    self.upsample1 = tf.keras.layers.UpSampling2D(size=2)\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    self.deconv = tf.keras.layers.Conv2D(filters=1, kernel_size=1, activation=tf.nn.relu, padding=\"same\")\n",
    "\n",
    "  def encoder_decoder(self, inputs, training=False):\n",
    "  \tx = self.conv1(inputs)\n",
    "  \tx = self.pool1(x)\n",
    "  \tx = self.conv2(x)\n",
    "  \tx = self.pool2(x)\n",
    "  \tx = self.conv3(x)\n",
    "  \tx = self.pool3(x)\n",
    "  \tx = self.deconv3(x)\n",
    "  \tx = self.upsample3(x)\n",
    "  \tx = self.deconv2(x)\n",
    "  \tx = self.upsample2(x)\n",
    "  \tx = self.deconv1(x)\n",
    "  \tx = self.upsample1(x)\n",
    "  \treturn x\n",
    "\n",
    "  def rgb_net(self, rgb):\n",
    "  \tx = self.convrgb(rgb)\n",
    "  \treturn x\n",
    "\n",
    "  def sparse_net(self, sparse_image):\n",
    "  \tx = self.convsparse(sparse_image)\n",
    "  \treturn x\n",
    "\n",
    "  def __call__(self, inputs, training=False):\n",
    "    with tf.variable_scope('keras_model'):\n",
    "      #rgb = inputs['rgb']\n",
    "      #sparse_depth = inputs['sparseInverseDepth']\n",
    "      #sparse_depth_var = inputs['sparseInverseDepthVariance']\n",
    "      rgb, sparse_depth, sparse_depth_var = inputs\n",
    "      x1 = self.rgb_net(rgb)\n",
    "      x2 = self.sparse_net(sparse_depth)\n",
    "      x3 = self.sparse_net(sparse_depth_var)\n",
    "      x = tf.keras.layers.concatenate( [x1,x2,x3])\n",
    "      x = self.encoder_decoder(x)\n",
    "      if training:\n",
    "        x = self.dropout(x)\n",
    "      return self.deconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def dataset_len(dataset_loc):\n",
    "    with open(dataset_loc) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"/misc/lmbraid19/thomasa/datasets/LSDDepthTraining/train/rgbd_lsdDepth_train.txt\"\n",
    "data_len = dataset_len(training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "steps_per_epoch = data_len // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_len)\n",
    "print(batch_size)\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 50\n",
    "print(\"num_steps = \", steps_per_epoch*num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idepth_prediction_file = \"/home/thomasa/Downloads/prediction.png\"\n",
    "idepth_gt_file = \"/home/thomasa/Downloads/gt2.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idepth_prediction = mpimg.imread(idepth_prediction_file)\n",
    "idepth_gt = mpimg.imread(idepth_gt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(idepth_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "norm = colors.Normalize(vmin=0, vmax=0.07)\n",
    "cmap = 'hot'\n",
    "images = []\n",
    "images.append(axs[0].imshow(idepth_prediction, cmap=cmap))\n",
    "images.append(axs[1].imshow(idepth_gt, cmap=cmap))\n",
    "for im in images:\n",
    "    im.set_norm(norm)\n",
    "fig.colorbar(images[0], ax=axs, orientation='horizontal', fraction=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
